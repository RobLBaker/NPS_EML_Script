{
  "articles": [
    {
      "path": "about.html",
      "title": "NPS EML Scripting",
      "description": "Resources and Guides for using EMLassemblyline to create EML for National Park Service data packages\n",
      "author": [
        {
          "name": "Robert Baker",
          "url": {}
        },
        {
          "name": "Judd Patterson",
          "url": {}
        }
      ],
      "date": "November 04, 2022",
      "contents": "\r\nThe NPS EML Script is an R script and accompanying documentation to facilitate using EMLassemblyline to generate EML metadata for data NPS packages prior to uploading to DataStore.\r\nTo report bugs or request enhancements, please use post an issue on github or email Rob Baker\r\n\r\n\r\n\r\n",
      "last_modified": "2022-11-04T15:53:44-06:00"
    },
    {
      "path": "comprehensive_guide.html",
      "title": "NPS EML Scripting",
      "description": "Resources and Guides for using EMLassemblyline to create EML for National Park Service data packages\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nComprehensive guide:\r\nNext Steps:\r\nAdditional Documentation\r\nAcknowledgements\r\n\r\nComprehensive guide:\r\nPrerequisites for EML metadata creation\r\nDownload the NPS EML Creation script and associated folders\r\nThis includes an NPS EML Script with example EML creation that you can edit/modify to generate your own EML\r\nTwo .csv data file inputs for the example:\r\nqry_Export_AA_Points.csv\r\nqry_Export_AA_VegetationDetails.csv\r\n\r\nA series of example .txt files that were generated using EMLassemblyline functions. These example files have already been edited to make the example EML files\r\nExample EML metadata file\r\n\r\n\r\nA step-by-step guide for using the NPS EML Creation Script\r\nReferences:\r\nGuidance on editing metadata templates (.txt files)\r\nFunctions for generating metadata templates\r\nA function to create EML metadata\r\n\r\nNext Steps:\r\nThe example EML file EVER_AA_metadata.xml as well as the EML you have created are not the final step in NPS EML creation. At this point you have filled in much of the important scientific information in the metadata. However, to fully utilize DataStore’s new capabilities and to make sure your data are easily discoverable and reusable, you still need to edit the EML file to provide NPS-specific information (e.g. publisher, unit connections, DOIs, etc). Currently, the only tool available is R/EMLeditor. Manually editing your metadata by hand is not recommended.\r\nFor a detailed workflow on how to use EMLeditor to generate the highest quality metadata, please see (under development)\r\nAdditional Documentation\r\nThe original EDI guidelines for creating EML.\r\nAdditional information about EML.\r\nThe official EML schema.\r\nAcknowledgements\r\nEMLassemblyline and much of the excellent original documentation was developed by the Environmental Data Initiative. We have modified and annotated that documentation to make it more relevant to NPS.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-11-04T15:53:48-06:00"
    },
    {
      "path": "create_eml.html",
      "title": "NPS EML Scripting",
      "description": "Resources and Guides for using EMLassemblyline to create EML for National Park Service data packages\n",
      "author": [],
      "contents": "\r\nThe make_eml() function renders templates (and input arguments) into EML metadata (click edi.260.1.xml for an example EML file).\r\nmake_eml() insists on access to the data objects to keep users from the monotonous mind-numbing task of gathering physical attributes (e.g. file size, number of rows, checksums, etc.) each time a data object changes. This enables automatic rebuild of revised data object EML as long as the structure remains constant (i.e. variable types and definitions don’t change, only new records are added). This highlights the benefit of creating data with stable attributes not to mention for the consideration of downstream user workflows depending on a specific input data structure.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-11-04T15:53:52-06:00"
    },
    {
      "path": "create_tmplts.html",
      "title": "NPS EML Scripting",
      "description": "Resources and Guides for using EMLassemblyline to create EML for National Park Service data packages\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nFunctions\r\nCore metadata\r\nTable attributes\r\nCategorical variables\r\nGeography\r\nTaxonomy\r\nProvenance\r\nAnnotations\r\n\r\n\r\nFunctions\r\nMetadata templates store content that is later converted to EML. Most templating functions read a data object, to extract as much information as possible, then writes it to file for the user to validate the inferred content and add any missing info. Each function focuses on a data feature enabling a modular build of the metadata (not all data contain the same features). The current set of templating functions are (click function names for docs):\r\nCore metadata\r\ntemplate_core_metadata() Describes core information of a data package (abstract, methods, keywords, personnel, license). Communicates what the data are, why and how they were created, who was involved in their creation, and under what terms the data may be used.\r\nTable attributes\r\ntemplate_table_attributes() Describes columns of a data table (classes, units, datetime formats, missing value codes).\r\nCategorical variables\r\ntemplate_categorical_variables() Describes categorical variables of a data table (if any columns are classified as categorical in table attributes template).\r\nGeography\r\ntemplate_geographic_coverage() Describes where the data were collected.\r\nTaxonomy\r\ntemplate_taxonomic_coverage() Describes biological organisms occurring in the data and helps resolve them to authority systems. If matches can be made, then the full taxonomic hierarchy of scientific and common names are automatically rendered in the final EML metadata. This enables future users to search on any taxonomic level of interest across data packages in repositories.\r\nProvenance\r\ntemplate_provenance() Describes source datasets. Explicitly listing the DOIs and/or URLs of input data help future users understand in greater detail how the derived data were created and may some day be able to assign attribution to the creators of referenced datasets.\r\nAnnotations\r\ntemplate_annotations() Adds semantic meaning to metadata (variables, locations, persons, etc.) through links to ontology terms. This enables greater human understanding and machine actionability (linked data) and greatly improves the discoverability and interoperability of data in general.\r\nNOTE: Data objects should be UTF-8 encoded so metadata extracted during the templating process will also be UTF-8, which is the required by the EML schema. Non-UTF-8 encoded data may result in metadata appearing as malformed character strings.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-11-04T15:53:55-06:00"
    },
    {
      "path": "edit_tmplts.html",
      "title": "NPS EML Scripting",
      "description": "Resources and Guides for using EMLassemblyline to create EML for National Park Service data packages\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nEditing EMLassemblyline-generated Templates\r\nabstract.txt\r\nmethods.txt\r\nkeywords.txt\r\npersonnel.txt\r\nintellectual_rights.txt\r\nattributes_*.txt\r\ncustom_units.txt\r\ncatvars_*.txt\r\ngeographic_coverage.txt\r\ntaxonomic_coverage.txt\r\nprovenance.txt\r\nannotations.txt\r\nadditional_info (.docx, .md, .txt)\r\n\r\n\r\nEditing EMLassemblyline-generated Templates\r\nMetadata inferred during the templating process should be validated by the user and missing info added. Use spreadsheet and text editors for this process. Template specific guides are listed below.\r\nNOTES:\r\nTemplates can be generated as .docx, .md, or .txt files. Here we focus on .txt. This is the default file format and also the simplest and least error-prone format.\r\nTabular templates: Leave empty cells blank, don’t fill with NAs.\r\nFree-text templates: Keep template content simple. Complex formatting can lead to errors.\r\nabstract.txt\r\nExample\r\nDescribes the salient features of a dataset in a concise summary much like an abstract does in a journal article. It should cover what the data are and why they were created. A good rule of thumb is that an abstract should be about 250 words or less. The abstract will become a publicly-facing piece of text featured on the DataStore reference page as well as sent on to DataCite, data.gov, and Google’s Dataset Search. A thoughtful and well-planned abstract may be useable not only for the data package but also for the Data Release Report (DRR).\r\nIf you write your abstract in a word processor (such as MS Word) and paste it in to the abstract.txt template file, please pass it through a text editor (such as Notepad) to make sure it is UTF-8 encoded and does not have special characters, including line breaks such as .\r\nNote: editing abstract.txt is best done via a text editor.\r\nmethods.txt\r\nExample\r\nDescribes the data creation methods. Includes enough detail for future users to correctly use the data. Lists instrument descriptions, protocols, etc. Methods sections can include citations. It may be appropriate to cite the Protocol, datasets that were ingested to generate the data package, software (e.g. R), packages (e.g. dplyr, ggplot2) or custom scripts.\r\nNote: editing methods.txt is best done via a text editor.\r\nkeywords.txt\r\nExample\r\nDescribes the data in a small set of terms. Keywords facilitate search and discovery on scientific terms, as well as names of research groups, field stations, and other organizations. Using a controlled vocabulary or thesaurus vastly improves discovery. We recommend using the LTER Controlled Vocabulary when possible.\r\nNote: editing keywords.txt is best done via a spreadsheet application.\r\nColumns:\r\nkeyword One keyword per line\r\nkeywordThesaurus URI of the vocabulary from which the keyword originates.\r\npersonnel.txt\r\nExample\r\nDescribes the personnel and funding sources involved in the creation of the data. This facilitates attribution and reporting.\r\nValid EML requires at least one person with a creator role. Creator is a synonym for Author in DataStore.\r\nDataStore also requires at least one person with the role if contact. If this is the same person, list that person twice (i.e. on two separate rows).\r\nAdditional personnel (field technicians, consultants, collaborators, contributers, etc) may be added to give credit as necessary. Any roles other than “creator” or “contact” will be listed as associatedParties.\r\nFor the purposes of NPS data packages, it is likely that you will not have Principle Investigators (PIs), or information about funding or funding agencies.\r\nNote: editing personnel.txt is best done through a spreadsheet application.\r\nColumns:\r\ngivenName First name\r\nmiddleInitial Middle initial\r\nsurName Last name\r\norganizationName Organization the person belongs to\r\nelectronicMailAddress Email address\r\nuserId Persons research identifier (e.g. ORCID). Links a persons research profile to a data publication.\r\nrole Role of the person with respect to the data. Persons serving more than one role are listed on separate lines (e.g. replicate the persons info on separate lines but change the role. Valid options:\r\ncreator Author(s) of the data. Will appear in the data citation.\r\nPI Principal investigator the data were created under. Will appear with project level metadata. It is OK to leave this blank as there will be no PIs for many NPS data packages.\r\ncontact A point of contact for questions about the data. Can be an organization or position (e.g. data manager). To do this, enter the organization or position name under givenName and leave middleInitial and surName empty.\r\nOther roles (e.g. Field Technician) will be listed as associated parties to the data. Their specific role (e.g. “data ranger” will also be listed in metadata)\r\n\r\nFunding information is listed with PIs\r\nprojectTitle Title of project the data were created under. If ancillary projects were involved, then add as new lines below the primary project with the PIs info replicated. This can typically be left blank.\r\nfundingAgency Agency the project was funded by. This can be left blank.\r\nfundingNumber Grant or award number. Likely leave this blank.\r\n\r\nintellectual_rights.txt\r\nExample\r\nYou must edit the “intellectual_rights.txt” file:\r\nIf the data package contains Controlled Unclassified Information (CUI), replace the CCO license in the .txt file with the following text:\r\n\r\n\r\n\r\n“This product has been determined to contain Controlled Unclassified Information (CUI) by the National Park Service, and is intended for internal use only. It is not published under an open license. Unauthorized access, use, and distribution are prohibited.”\r\n\r\nIf you have no CUI, the default is the public domain. Replace the CCO text in the .txt file with the following text:\r\n\r\n“This work is in the public domain. There is no copy right or license.”\r\n\r\nIf you need a license, for instance because the data were generated by non-NPS contractors or in collaboration with non-NPS partners, use the text generated by template_core_metadata (license=“CCO”).\r\nMore information about the (CC0) license.\r\nNote: editing the intellectual_rights.txt file is best done through a text editor.\r\nattributes_*.txt\r\nExample 1, Example 2\r\nIf you have multiple data files (.csvs), multiple text files will be generated, each starting with “attributes”, followed by your csv file name, and having the extension “.txt”. These files Describe columns of a data table (classes, units, datetime formats, missing value codes).\r\nNote: editing attribute_.txt is best done using a spreadsheet application.\r\nColumns:\r\nattributeName Column name. Make sure that each column has an attributeName and tha they match (including case sensitivity)\r\nattributeDefinition Column definition\r\nclass Column class. Valid options are:\r\nnumeric Numeric variable\r\ncategorical Categorical variable (i.e. nominal)\r\ncharacter Free text character strings (e.g. notes)\r\nDate Date and time variable\r\n\r\nunit Column unit. Required for numeric classes. Select from EML’s standard unit dictionary, accessible with view_unit_dictionary(). Use values in the “id” column. If not found, then define as a custom unit (see custom_units.txt).\r\ndateTimeFormatString Format string. Required for Date classes. Valid format string components are:\r\nY Year\r\nM Month\r\nD Day\r\nh Hour\r\nm Minute\r\ns Second\r\nCommon separators of format string components (e.g. - /  :) are supported.\r\n\r\nmissingValueCode Missing value code. Required for columns containing a missing value code).\r\nmissingValueCodeExplanation Definition of missing value code.\r\ncustom_units.txt\r\nExample\r\nDescribes non-standard units used in a data table attribute template.\r\nNote: custom-units.txt is best edited via a spreadsheet application.\r\nColumns:\r\nid Unit name listed in the unit column of the table attributes template (e.g. feetPerSecond)\r\nunitType Unit type (e.g. velocity)\r\nparentSI SI equivalent (e.g. metersPerSecond)\r\nmultiplierToSI Multiplier to SI equivalent (e.g. 0.3048)\r\ndescription Abbreviation (e.g. ft/s)\r\ncatvars_*.txt\r\nExample 1, Example 2\r\nDescribes categorical variables of a data table (if any columns are classified as categorical in table attributes template). If you have multiple data files (csvs), multiple catvars files will be created, one for each csv.\r\nNote: The catvars files are best edited with a spreadsheet application.\r\nColumns:\r\nattributeName Column name\r\ncode Categorical variable\r\ndefinition Definition of categorical variable\r\ngeographic_coverage.txt\r\nExample\r\nDescribes where the data were collected.\r\nNote: Hopefully you don’t have to edit these.\r\nColumns:\r\ngeographicDescription Brief description of location.\r\nnorthBoundingCoordinate North coordinate\r\nsouthBoundingCoordinate South coordinate\r\neastBoundingCoordinate East coordinate\r\nwestBoundingCoordinate West coordinate\r\nCoordinates must be in decimal degrees and include a minus sign (-) for latitudes south of the equator and longitudes west of the prime meridian. For points, repeat latitude and longitude coordinates in respective north/south and east/west columns. If you need to convert from UTMs, try using the UTMtoLL function in the R/QCkit package.\r\nCurrently EML handles points and rectangles well. At the least precise end of spectrum you could enter an entire park unit as geographic For a convenient way to get these coordinates, see the get.unitPolygon function in the R/EMLeditor package.\r\nWe strongly encourage you to be as precise as possible with your geographicCoverage and provide sampling pionts (e.g. along a transect) whenever possible. This information will (eventually) be displayed on a map on the DataStore Reference page for the data package and these points will also be directly discoverable through DataStore searches.\r\nIf you have CUI concerns about the specific locations of your sites, consider fuzzing them rather than completely removing them. One good tool for fuzzing geographic coordinates is the dp_fuzzLocation function in the R/QCkit package.\r\ntaxonomic_coverage.txt\r\nExample\r\nDescribes biological organisms occurring in the data and helps resolve them to authority systems. If matches can be made, then the full taxonomic hierarchy of scientific and common names are automatically rendered in the final EML metadata. This enables future users to search on any taxonomic level of interest across data packages in repositories.\r\nNote: Hopefully you don’t have to edit these.\r\nColumns:\r\ntaxa_raw Taxon name as it occurs in the data and as it will be listed in the metadata if no value is listed under the name_resolved column. Can be single word or species binomial.\r\nname_type Type of name. Can be “scientific” or “common”.\r\nname_resolved Taxons name as found in an authority system.\r\nauthority_system Authority system in which the taxa’s name was found. Can be: “ITIS”, “WORMS”, “or”GBIF“.\r\nauthority_id Taxa’s identifier in the authority system (e.g. 168469).\r\nprovenance.txt\r\nExample\r\nDescribes source datasets. Explicitly listing the DOIs and/or URLs of input data help future users understand in greater detail how the derived data were created and may some day be able to assign attribution to the creators of referenced datasets.\r\nProvenance metadata can be automatically generated for supported repositories simply by specifying an identifier (i.e. EDI) in the systemID column. For unsupported repositories (e.g. DataStore), the systemID column should be left blank.\r\nFor many monitoring protocols, there may not be any input datasets, instead the data package is based on newly collected & original data. In this case, leave provenance.txt blank.\r\nColumns:\r\ndataPackageID Data package identifier. Supplying a valid packageID and systemID (of supported systems) is all that is needed to create a complete provenance record.\r\nsystemID System (i.e. data repository) identifier. Currently supported systems are: EDI (Environmental Data Initiative). Leave this column blank unless specifying a supported system.\r\nurl URL linking to an online source (i.e. data, paper, etc.). Required when a source can’t be defined by a packageID and systemID.\r\nonlineDescription Description of the data source. Required when a source can’t be defined by a packageID and systemID.\r\ntitle The source title. Required when a source can’t be defined by a packageID and systemID.\r\ngivenName A creator or contacts given name. Required when a source can’t be defined by a packageID and systemID.\r\nmiddleInitial A creator or contacts middle initial. Required when a source can’t be defined by a packageID and systemID.\r\nsurName A creator or contacts middle initial. Required when a source can’t be defined by a packageID and systemID.\r\nrole “creator” and “contact” of the data source. Required when a source can’t be defined by a packageID and systemID. Add both the creator and contact as separate rows within the template, where the information in each row is duplicated except for the givenName, middleInitial, surName (or organizationName), and role fields.\r\norganizationName Name of organization the creator or contact belongs to. Required when a source can’t be defined by a packageID and systemID.\r\nemail Email of the creator or contact. Required when a source can’t be defined by a packageID and systemID.\r\nannotations.txt\r\nExample\r\nAdds semantic meaning to metadata (variables, locations, persons, etc.) through links to ontology terms. This enables greater human understanding and machine actionability (linked data) and greatly improves the discoverability and interoperability of data in general.\r\nColumns:\r\nid A unique identifier for the element being annotated.\r\nelement The element being annotated.\r\ncontext The context of the subject (i.e. element value) being annotated (e.g. If the same column name occurs in more than one data tables, you will need to know which table it came from.).\r\nsubject The element value to be annotated.\r\npredicate_label The predicate label (a.k.a. property) describing the relation of the subject to the object. This label should be copied directly from an ontology.\r\npredicate_uri The predicate label URI copied directly from an ontology.\r\nobject_label The object label (a.k.a. value) describing the subject. This label should be copied directly from an ontology.\r\nobject_uri The object URI copied from an ontology.\r\nadditional_info (.docx, .md, .txt)\r\nExample\r\nAncillary info not captured by any of the other templates.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-11-04T15:54:00-06:00"
    },
    {
      "path": "index.html",
      "title": "NPS EML Scripting",
      "description": "Resources and Guides for using EMLassemblyline to create EML for National Park Service data packages\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nOverview\r\nQuickstart\r\nComprehensive guide\r\nAdditional Documentation\r\nAcknowledgements\r\n\r\n\r\nOverview\r\nCreating Ecological Metadata Language (EML) metadata for NPS data packages is a two-step process.\r\nThe first step is to generate an EML formatted .xml file. There are a number of tools for generating this initial file. This repo contains an R script, instructions, and an example of how to use EMLassemblyline to generate an initial EML metadata file while taking into consideration NPS data package specifications and requirements for uploading to DataStore.\r\nNo matter the method of generating the initial EML file, the second step is to add NPS-specific information to the EML metadata (for instance, the data pacakge DOI, links to the DRR, information about CUI, producing units and unit connections). Currently, the only tool for adding NPS-specific metadata is the R/EMLeditor package. Editing EML by hand is not advised.\r\nThis is an early version of this template. Please request enhancements and bug fixes through Issues.\r\nYou can also directly access the source files for this webpage and the entire repo, as well as download the entire repo as zip file.\r\nQuickstart\r\nTo jump right into creating EML, check out our quickstart quide.\r\nComprehensive guide\r\nFor more details including:\r\n* Prerequisites and installation instructions\r\n* A step-by-step guide\r\n* Example files and code as well as examples of results\r\n* Detailed examples on how to edit templates\r\n* Much, much more\r\nPlease see the Comprehensive Guide to using EMLassemblyline for NPS metadata creation.\r\nAdditional Documentation\r\nThe original EDI guidelines for creating EML.\r\nAdditional information about EML.\r\nThe official EML schema.\r\nAcknowledgements\r\nEMLassemblyline and much of the excellent original documentation was developed by the Environmental Data Initiative. We have simply modified and annotated that documentation to make it more relevant to NPS.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-11-04T15:54:02-06:00"
    },
    {
      "path": "organize_data_package.html",
      "title": "NPS EML Scripting",
      "description": "Resources and Guides for using EMLassemblyline to create EML for National Park Service data packages\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nThe data package\r\nAn organization scheme\r\n\r\nThe data package\r\nA data package forms a collection of data objects and metadata enabling understanding, use, and citation of a dataset. Metadata play an important role in understanding each object and how they relate to each other. EAL works for all digital object formats and has been used by the Environmental Data Initiative (EDI) to create and manage over 500 data packages for a nearly equal number of researchers. Revising data packages with EAL is easy but requires some forethought about file organization.\r\nAn organization scheme\r\nA useful organization scheme is a single directory for each data package containing:\r\ndata_objects A directory of data and other digital objects to be packaged (e.g. data files, scripts, .zip files, etc.).\r\nmetadata_templates A directory of EAL template files.\r\neml A directory of EML files created by EAL.\r\nrun_EMLassemblyline.R An R file for scripting an EAL workflow.\r\nRun template_directories() to create this organization scheme.\r\nAn even simpler organization scheme, albeit more cluttered, is a single directory containing all files belonging to a data package. A third option is to customize file location, use the path, data.path, and eml.path arguments of EAL functions.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-11-04T15:54:05-06:00"
    },
    {
      "path": "prereqs.html",
      "title": "NPS EML Scripting",
      "description": "Resources and Guides for using EMLassemblyline to create EML for National Park Service data packages\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nData\r\nSoftware\r\nInternet access\r\nMS excel\r\nA text editor\r\n\r\nPrior to generating EML you will need the following:\r\nData\r\nA set of fully QA/QC’d data files in .csv format. If these are exported from a database, you may want to think strategically about what those files look like and how they will be accessed and utilized by future users of the data package (including, potentially, yourself!). It is worth running through the example metadata creation to understand how these files will be used.\r\nData files must be encoded in UTF-8 format. If aren’t sure whether your .csvs are in UTF-8 you can convert them to UTF-8. Opening the .csv in Excel, then choose to File from the main menu and the “Save As” option. Finally, select “CSV UTF-8 (Comma delimited) (*.csv)“) as the file format from the drop-down menu.\r\nAll of your files for a single data pakage must be in the same directory. There should be no additional .csv files in this directory.\r\nSoftware\r\nInstall R (and probably Rstudio) installed on your computer. These are both available in Software Center. See the R Advisory Group’s website for more information. You will also need to install the R package EMLassemblyline as well as some other packages from CRAN. Many of these are available as part of the NPSdataverse package.\r\n\r\n\r\n#install packages:\r\ninstall.packages(c(\"devtools\", \"lubridate\", \"tidyverse\"))\r\nlibrary(devtools)\r\n\r\n#the NPSdataverse includes EMLassemblyline and several other useful packages:\r\ninstall_github(\"nationalparkservice/NPSdataverse\")\r\n\r\nlibrary(\"lubridate\", \"tidyverse\", \"NPSdataverse\")\r\n\r\n\r\nInternet access\r\nA strong internet connection, particularly if you have taxonomic information. EMLassemblyline do API searches of various taxonomic databases and use the scientific names in your data files to populate taxonomic coverage fields from Kingdom down to species (and beyond).\r\nMS excel\r\nAccess to MS excel (or any other spreadsheet type program). This will really help editing the tab-delimited .txt template files generated while using EMLassemblyline.\r\nA text editor\r\nAccess to notepad or other text editor (NOT MS Word) for writing abstracts, etc. while avoiding non-UTF-8 encoded characters.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-11-04T15:54:09-06:00"
    },
    {
      "path": "quick_start.html",
      "title": "NPS EML Scripting",
      "description": "Resources and Guides for using EMLassemblyline to create EML for National Park Service data packages\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nQuickstart\r\nPrior to generating EML you will need the following:\r\nDownload the Script\r\nGenerate EML\r\nNext steps\r\n\r\nAdditional documentation\r\nAcknowledgements\r\n\r\nQuickstart\r\nPrior to generating EML you will need the following:\r\nData: A set of fully QA/QC’d data files in .csv format using UTF-8 encoding.\r\nInternet access: for downloading software and packages. A strong internet connection is necessary, particularly if you have taxonomic information as EMLassemblyline will use scientific names to reach out to ITIS and/or GBIF to populate taxonomic coverage fields from Kingdom down to species (and beyond).\r\nSoftware: R (and probably RStudio) installed on your computer. These are both available in Software Center. See the R Advisory Group’s website for more information. You will also need to install the R package EMLassemblyline from GitHub as well as some other packages from CRAN. These can all be installed at once using the R package NPSdataverse:\r\n\r\n#install packages:\r\ninstall.packages(c(\"devtools\", \"lubridate\", \"tidyverse\"))\r\nlibrary(devtools)\r\n\r\n#the NPSdataverse includes EMLassemblyline and several other useful packages:\r\ninstall_github(\"nationalparkservice/NPSdataverse\")\r\n\r\nlibrary(\"lubridate\", \"tidyverse\", \"NPSdataverse\")S\r\n\r\nAccess to MS Excel (or any spreadsheet type programs) and Notepad (or any text editor). These will facilitate editing tab-delimited files.\r\nDownload the Script\r\nA stand-alone version of the NPS EML Creation script is available for download. You don’t have to download the entire repository to make EML.\r\nGenerate EML\r\nEdit the EML_Creation_Script.R file as necessary and run each line or set of code (except the make_eml function).\r\nEdit the auto-generated .txt files using a text editor or spreadsheet application as necessary. For details, look at the NPS template editing guideline.\r\nRun the make_eml function (this could take a little while - particularly if you have a lot of taxonomic data).\r\nBe sure to read and address any Issues or Warnings after running the make_eml function.\r\nNext steps\r\nThe EML you have created is not the final step in NPS EML creation. To fully utilize DataStore’s new capabilities and to make sure your data are easily discoverable and reusable, you still need to edit the EML file to provide NPS-specific information (e.g. publisher, unit connections, DOIs, etc).\r\nCurrently, the only tool available to add NPS-specific information to EML is R/EMLeditor. Manually editing your metadata by hand is not recommended.\r\nAdditional documentation\r\nThe Comprehensive guide to using the NPS EML creation script.\r\nThe original EDI guidelines for creating EML.\r\nAcknowledgements\r\nEMLassemblyline and much of the excellent original documentation was developed by the Environmental Data Initiative. We have modified and annotated that documentation to make it more relevant to NPS.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-11-04T15:54:12-06:00"
    },
    {
      "path": "stepbystep.html",
      "title": "NPS EML Scripting",
      "description": "Resources and Guides for using EMLassemblyline to create EML for National Park Service data packages\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nStep-by-step-guide\r\nSummary\r\nBefore you Start\r\nInstall Required Software\r\nInitiate a Draft Reference in DataStore\r\n\r\nUsing the Template\r\nProvide Information About the Data Package\r\nFiles: Local path\r\nFiles: Ultimate URL\r\nGeographic Coordinates\r\nStart and End Dates\r\nEMLassembly Functions\r\nFunction 1: Core metadata\r\nFunction 2: Attributes\r\nFunction 3: Categoricals\r\nFunction 4: Geography\r\nFunction 5: Taxonomy\r\n\r\nMake EML function\r\n\r\nFinished? Not quite…\r\n\r\nStep-by-step-guide\r\nSummary\r\nThis code creates an EML file for a data package. In this case the example is an EVER AA dataset, which consists of two data files, both located in the Example_files folder:\r\nqry_Export_AA_Points.csv\r\nqr_Export_AA_VegetationDetails.csv\r\nThis is a step by step process where each section should be reviewed and edited if necessary, and run one by one. Several sections are labeled as DECISION POINTS and may only apply to certain data packages.\r\nThe final section has the make_eml() function to put together the full metadata file.\r\nBefore you Start\r\nInstall Required Software\r\nYou will need to install R and may find RStudio helpful. Both can be installed from Software Center without need for admin rights on your machine. For more information, see the R Advisory Group’s website.\r\nIf you’ve never installed EMLassemblyline, you’ll needed to install it (as well as some other packages) and then load them into R’s working memory:\r\n\r\n\r\n## install necessary packages:\r\ninstall.packages(c(\"devtools\", \"lubridate\", \"tidyverse\", \"stringr\"))\r\nlibrary(devtools)\r\ndevtools::install_github(\"EDIorg/EMLassemblyline\")\r\n  \r\n#Load required packages\r\nlibrary(EMLassemblyline)\r\nlibrary(lubridate)\r\nlibrary(tidyverse)\r\nlibrary(stringr)\r\n\r\n\r\nInitiate a Draft Reference in DataStore\r\nYou will need to know the URLs of your data files. These will be located on DataStore. Got to DataStore, select “Create” from the green drop down menu and then choose “Draft Reference”. For now, select “Tabular Dataset” as the reference type (Data Package Reference Type coming soon!). Make sure to take note of the 7-digit code for the Reference as you will need it later.\r\nDon’t activate the reference yet!\r\nUsing the Template\r\nProvide Information About the Data Package\r\n\r\n\r\n#Metadata filename - this becomes the filename, so make sure it ends in _metadata to comply with the NPS data package specifications\r\nmetadata_id <- \"TEST_EVER_AA_metadata\"\r\n\r\n#Overall package title (replace with your title).\r\npackage_title <- \"TEST_Title\"\r\n\r\n#Description of data collection status - choose from 'ongoing' or 'complete'\r\ndata_type <- \"complete\"\r\n\r\n\r\nFiles: Local path\r\nTell EMLassemblyline where your files are (and what they are).\r\nFor vectors with more than one item, keep the order the same (i.e. item #1 should correspond to the same file in each vector).\r\n\r\n\r\n#Path to data file(s). The default \"getwd()\" assumes that your working directory in R is the directory where your data files for your data package are.\r\n\r\n#to check your current working directory use getwd()\r\n\r\n#To change your working directory use >setwd(\"path/to/my/datafiles\"). \r\n\r\n#Alternatively you can continue working in your current directory and assign the path to your data files to 'working_folder' instead of 'getwd()'\r\nworking_folder <- getwd()\r\n\r\n#Vector of dataset filenames. Tell EMLassemblyline what the names of your datafiles are. Watch out for spelling and case. \r\ndata_files <- c(\"qry_Export_AA_Points.csv\", \"qry_Export_AA_VegetationDetail.csv\")\r\n  \r\n#Vector of dataset names (brief name for each file). Make sure the names of are in the same order as the file names!\r\ndata_names <- c(\"TEST_AA Point Data\",\"TEST_AA Vegetation Data\")\r\n  \r\n#Vector of dataset descriptions (about 10 words describing each file). Descriptions will be used in auto-generated tables within the ReadMe and DRR. If need to use more than about 10 words, consider putting that information in the abstract, methods, or additional info sections. Again, be sure these are in the same order as your data files!\r\ndata_descriptions <- c(\"TEST_Everglades Vegetation Map Accuracy Assessment point data\",\"Everglades Vegetation Map Accuracy Assessment vegetation data\")\r\n\r\n\r\nFiles: Ultimate URL\r\nTell EMLassemblyline where your files will ultimately be located.\r\nCreate a vector of dataset URLs - for DataStore I recommend setting this to the main reference page. All data files from a single data package can be accessed from the same page so the URLs are the same.\r\n\r\n\r\n#The code from the draft reference you initiated above (replace 293181 with your code)\r\nDSRefCode<-2293181\r\n\r\n#No need to edit this\r\nDSURL<-paste0(\"https://irma.nps.gov/DataStore/Reference/Profile/\", DSRefCode)\r\n\r\n#No need to edit this\r\nDSURL<-paste0(\"https://irma.nps.gov/DataStore/Reference/Profile/\", DSRefCode)\r\n\r\n\r\nTell EMLassembly line where to find the table and field that contains scientific names. These will be used to fill the taxonomic coverage metadata. If you don’t have scientific names (e.g. water quality), skip this step and do not run OPTIONAL 5 (below).\r\n\r\n\r\ndata_taxa_table <- \"qry_Export_AA_VegetationDetail.csv\"\r\ndata_taxa_field <- \"Scientific_Name\"\r\n\r\n\r\nGeographic Coordinates\r\nTell EMLassemblyline where to find the table and fields that contain the geographic coordinates and site names that can be used to fill the geographic coverage metadata. Comment these out and do not run OPTIONAL 4 (below) if your data package does not contain geographic information.\r\nCoordinates must be in decimal degrees and include a minus sign (-) for latitudes south of the equator and longitudes west of the prime meridian. For points, repeat latitude and longitude coordinates in respective north/south and east/west columns. If you need to convert from UTMs, try using the UTMtoLL function in the R/QCkit package.\r\nThe example below will generate a single point for each site. We strongly encourage you to be as precise as possible with your geographicCoverage and provide sampling pionts (e.g. along a transect) whenever possible. This information will (eventually) be displayed on a map on the DataStore Reference page for the data package and these points will also be directly discoverable through DataStore searches.\r\nIf you have CUI concerns about the specific locations of your sites, consider fuzzing them rather than completely removing them. One good tool for fuzzing geographic coordinates is the dp_fuzzLocation function in the R/QCkit package.\r\n\r\n\r\ndata_coordinates_table <- \"qry_Export_AA_Points.csv\"\r\ndata_latitude <- \"decimalLatitude\"\r\ndata_longitude <- \"decimalLongitude\"\r\ndata_sitename <- \"Point_ID\"\r\n\r\n\r\nStart and End Dates\r\nThe start date and end date This should indicate the first and last data point in the data package (across all files) and does not include any planning, pre- or post-processing time. The format should be one that complies with the International Standards Organization’s standard 8601. The recommended format for EML is:\r\n#YYYY-MM-DD, where Y is the four digit year, M is the two digit month code (01 - 12 for example, January = 01), and D is the two digit day of the month (01 - 31).\r\n\r\n\r\nstartdate <- ymd(\"2010-01-26\")\r\nenddate <- ymd(\"2013-01-04\")\r\n\r\n\r\nEMLassembly Functions\r\nThe next set of optional items are meant to be considered one by one and only run if applicable to a particular data package. The first year will typically see all of these run, but if the data format and protocol stays constant over time it may be possible to skip some or all of these in future years.\r\nFunction 1: Core metadata\r\nCreates blank TXT template files for the abstract, additional information, custom units, intellectual rights, keywords, methods, and personnel. Some of these .txt files are easily edited in text editors (e.g. abstract.txt) but some are best edited in Excel (or another spreadsheet application), for instance the personnel.txt file.\r\nFor specific guidance on editing these templates, see the documentation on editing templates.\r\nTypically these files can be reused between years.\r\nYou must edit the “intellectual_rights.txt” file:\r\nIf you have CUI, replace the CCO license with the following text:\r\n\r\n\r\n\r\n“This product has been determined to contain Controlled Unclassified Information (CUI) by the National Park Service, and is intended for internal use only. It is not published under an open license. Unauthorized access, use, and distribution are prohibited.”\r\n\r\nIf you have no CUI, the default is the public domain. Replace the CCO text with the following text:\r\n\r\n“This work is in the public domain. There is no copy right or license.”\r\n\r\nIf you need a license, for instance because the data were generated by non-NPS contractors or in collaboration with non-NPS partners, use the default license=“CCO”.\r\n\r\n\r\ntemplate_core_metadata(path = working_folder, \r\n                       license = \"CC0\")\r\n\r\n\r\nFunction 2: Attributes\r\nCreates an “attributes_datafilename.txt” file for each data file. This can be opened in Excel (We recommend against trying to update these in a text editor) and fill in/adjust the columns for attributeDefinition, class, unit, etc. refer to the webpage on editing templates for helpful hints and use EMLassemblyline::view_unit_dictionary() for potential units. This will only need to be run again if the attributes (name, order or new/deleted fields) are modified from the previous year. NOTE that if this already exists from a previous run, it is not overwritten.\r\n\r\n\r\ntemplate_table_attributes(path = working_folder,\r\n                          data.table = data_files,\r\n                          write.file = TRUE)\r\n\r\n\r\nFunction 3: Categoricals\r\nCreates a “catvars_datafilename.txt” file for each data file that has columns with a class = categorical. These txt files will include each unique ‘code’ and allow input of the corresponding ‘definition’.NOTE that since the list of codes is harvested from the data itself, it’s possible that additional codes may have been relevant/possible but they are not automatically included here. Consider your lookup lists carefully to see if additional options should be included (e.g if your dataset DPL values are all set to “Accepted” this function will not include “Raw” or “Provisional” in the resulting file and you may want to add those manually). NOTE that if this already exists from a previous run, it is not overwritten.\r\n\r\n\r\ntemplate_categorical_variables(path = working_folder,\r\n                               data.path = working_folder, \r\n                               write.file = TRUE)\r\n\r\n\r\nFunction 4: Geography\r\nCreates a geographic_coverage.txt file that lists your sites as points as long as your coordinates are in lat/long. If your coordinates are in UTM it is probably easiest to convert them first or create the geographic_coverage.txt file another way. For isntance, try using the UTMtoLL function in R/QCkit.\r\n\r\n\r\ntemplate_geographic_coverage(path = working_folder, \r\n                             data.path = working_folder, \r\n                             data.table = data_coordinates_table, \r\n                             lat.col = data_latitude, \r\n                             lon.col = data_longitude, \r\n                             site.col = data_sitename, \r\n                             write.file = TRUE)\r\n\r\n\r\nFunction 5: Taxonomy\r\nCreates a taxonomic_coverage.txt file if you have taxonomic data. In terms of authorities 3 = ITIS, 9 = WORMS, and 11 = GBIF. Turning this function on may dramatically increase the time it takes for the make_eml() function to run, especially if you have many taxa or a slow internet connection. You may want to consider turning this off for testing/development purposes.\r\n\r\n\r\ntemplate_taxonomic_coverage(path = working_folder, \r\n                            data.path = working_folder, \r\n                            taxa.table = data_taxa_table, \r\n                            taxa.col = data_taxa_field, \r\n                            taxa.authority = c(3,11), \r\n                            taxa.name.type = 'scientific', \r\n                            write.file = TRUE)\r\n\r\n\r\nMake EML function\r\nRun this (it may take a little while) and see if it validates (you should see ‘Validation passed’). Additionally there could be some issues that review as well. Run the function ‘issues()’ at the end of the process to get feedback on items that might be missing.\r\n\r\n\r\nmake_eml(path = working_folder,\r\n           dataset.title = package_title,\r\n           data.table = data_files,\r\n           data.table.name = data_names,\r\n           data.table.description = data_descriptions,\r\n           data.table.url = data_urls,\r\n           temporal.coverage = c(startdate, enddate),\r\n           maintenance.description = data_type,\r\n           package.id = metadata_id)\r\n\r\n\r\nFinished? Not quite…\r\nNow that you have valid EML metadata, you need to add NPS-specific elements and fields. For instance, unit connections, DOIs, referencing a DRR, etc. To do that, use the R/EMLeditor package.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-11-04T15:54:16-06:00"
    }
  ],
  "collections": []
}
